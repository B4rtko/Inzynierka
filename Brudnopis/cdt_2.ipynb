{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "from src import *\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "         Data  Otwarcie  Najwyzszy  Najnizszy  Zamkniecie    Wolumen\n0  1997-02-06    1717.2     1779.8     1717.2      1779.8  4435886.0\n1  1997-02-07    1778.2     1808.7     1778.2      1799.0  5448243.0\n2  1997-02-10    1797.4     1797.4     1780.3      1783.3  6513315.0\n3  1997-02-11    1803.3     1832.2     1803.3      1832.0  5146340.0\n4  1997-02-12    1824.6     1824.6     1804.9      1810.2  5748398.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Otwarcie</th>\n      <th>Najwyzszy</th>\n      <th>Najnizszy</th>\n      <th>Zamkniecie</th>\n      <th>Wolumen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1997-02-06</td>\n      <td>1717.2</td>\n      <td>1779.8</td>\n      <td>1717.2</td>\n      <td>1779.8</td>\n      <td>4435886.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1997-02-07</td>\n      <td>1778.2</td>\n      <td>1808.7</td>\n      <td>1778.2</td>\n      <td>1799.0</td>\n      <td>5448243.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1997-02-10</td>\n      <td>1797.4</td>\n      <td>1797.4</td>\n      <td>1780.3</td>\n      <td>1783.3</td>\n      <td>6513315.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1997-02-11</td>\n      <td>1803.3</td>\n      <td>1832.2</td>\n      <td>1803.3</td>\n      <td>1832.0</td>\n      <td>5146340.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1997-02-12</td>\n      <td>1824.6</td>\n      <td>1824.6</td>\n      <td>1804.9</td>\n      <td>1810.2</td>\n      <td>5748398.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.read_csv(\"Data/wig20_d.csv\")\n",
    "# df = pd.read_csv(\"Data/mwig40_d.csv\")\n",
    "# df = pd.read_csv(\"Data/swig80_d.csv\")\n",
    "\n",
    "_df.drop(range(1000), inplace=True)\n",
    "_df.reset_index(inplace=True, drop=True)\n",
    "_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 6429)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = _df.drop(columns=[\"Data\"]).values.transpose()\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process and split data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_pipeline = DataProcess(data, test_ratio=0.2, validation_ratio=0.2, batch_size=32, threshold_fall=-0.007, threshold_rise=0.007)\n",
    "data_pipeline.run()\n",
    "_x_train, _y_train, _x_test, _y_test, _x_validation, _y_validation = data_pipeline.get_data()\n",
    "_y_test_ind, _y_validation_ind = np.argmax(_y_test, axis=1), np.argmax(_y_validation, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                           x          y\ntrain       (3825, 5, 32, 2)  (3825, 3)\ntest        (1254, 5, 32, 2)  (1254, 3)\nvalidation  (1254, 5, 32, 2)  (1254, 3)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>(3825, 5, 32, 2)</td>\n      <td>(3825, 3)</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>(1254, 5, 32, 2)</td>\n      <td>(1254, 3)</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>(1254, 5, 32, 2)</td>\n      <td>(1254, 3)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"x\": [_x_train.shape, _x_test.shape, _x_validation.shape],\n",
    "        \"y\": [_y_train.shape, _y_test.shape, _y_validation.shape]\n",
    "    },\n",
    "    index = [\"train\", \"test\", \"validation\"]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset classes value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": "          0     1     2\ncount  1148  1490  1187",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1148</td>\n      <td>1490</td>\n      <td>1187</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train dataset classes value counts:\")\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        str(key): val for (key, val) in zip(*np.unique(np.argmax(_y_train, axis=1), return_counts=True))\n",
    "    },\n",
    "    index = [\"count\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=_x_train.shape[1:]))\n",
    "for i in range(7):\n",
    "    model.add(tf.keras.layers.Conv2D(2, (1, 3), 1, padding=\"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 3), strides=(1, 3), padding='same'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(12))\n",
    "model.add(tf.keras.layers.Dense(7))\n",
    "model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "#model.add(tf.keras.layers.Dense(2))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model.build(input_shape=_x_train.shape[1:])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 5, 32, 2)          14        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 5, 11, 2)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 11, 2)          14        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 4, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 5, 4, 2)           14        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 2, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 2, 2)           14        \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 1, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 1, 2)           14        \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 1, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 5, 1, 2)           14        \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 1, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 5, 1, 2)           14        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 5, 1, 2)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                132       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 91        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 345\n",
      "Trainable params: 345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#               loss=tf.keras.losses.MeanSquaredError())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=f1_m)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.Poisson())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "120/120 [==============================] - 2s 8ms/step - loss: 279738.2188 - f1_m: 0.3818\n",
      "Epoch 2/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 14767.5381 - f1_m: 0.3386\n",
      "Epoch 3/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 12475.2363 - f1_m: 0.3375\n",
      "Epoch 4/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 11149.2266 - f1_m: 0.3339\n",
      "Epoch 5/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 9632.4395 - f1_m: 0.3334\n",
      "Epoch 6/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 9038.2061 - f1_m: 0.3230\n",
      "Epoch 7/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 7119.8853 - f1_m: 0.3445\n",
      "Epoch 8/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 6748.4434 - f1_m: 0.3441\n",
      "Epoch 9/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 5627.0049 - f1_m: 0.3430\n",
      "Epoch 10/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4854.7188 - f1_m: 0.3378\n",
      "Epoch 11/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4714.1860 - f1_m: 0.3239\n",
      "Epoch 12/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3899.3174 - f1_m: 0.3304\n",
      "Epoch 13/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3615.1184 - f1_m: 0.3301\n",
      "Epoch 14/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2914.6265 - f1_m: 0.3360\n",
      "Epoch 15/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2398.8398 - f1_m: 0.3386\n",
      "Epoch 16/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 2044.3766 - f1_m: 0.3384\n",
      "Epoch 17/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1674.7097 - f1_m: 0.3478\n",
      "Epoch 18/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1488.0909 - f1_m: 0.3528\n",
      "Epoch 19/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1849.1055 - f1_m: 0.3414\n",
      "Epoch 20/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1408.1747 - f1_m: 0.3280\n",
      "Epoch 21/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1170.4827 - f1_m: 0.3454\n",
      "Epoch 22/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1133.8248 - f1_m: 0.3391\n",
      "Epoch 23/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 2049.7961 - f1_m: 0.3390\n",
      "Epoch 24/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1943.5431 - f1_m: 0.3412\n",
      "Epoch 25/150\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1383.5664 - f1_m: 0.3436\n",
      "Epoch 26/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1877.5441 - f1_m: 0.3249\n",
      "Epoch 27/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1037.3226 - f1_m: 0.3350\n",
      "Epoch 28/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1166.7839 - f1_m: 0.3486\n",
      "Epoch 29/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1533.7733 - f1_m: 0.3402\n",
      "Epoch 30/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 1281.5446 - f1_m: 0.3343\n",
      "Epoch 31/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1040.1300 - f1_m: 0.3485\n",
      "Epoch 32/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1428.3582 - f1_m: 0.3321\n",
      "Epoch 33/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 1158.9789 - f1_m: 0.3439\n",
      "Epoch 34/150\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 871.5157 - f1_m: 0.3433\n",
      "Epoch 35/150\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1026.5829 - f1_m: 0.3329\n",
      "Epoch 36/150\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 1209.7734 - f1_m: 0.3324\n",
      "Epoch 37/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 862.5440 - f1_m: 0.3389\n",
      "Epoch 38/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 799.4240 - f1_m: 0.3587\n",
      "Epoch 39/150\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 1062.8322 - f1_m: 0.3272\n",
      "Epoch 40/150\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 885.3594 - f1_m: 0.3441\n",
      "Epoch 41/150\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 797.7240 - f1_m: 0.3445\n",
      "Epoch 42/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 663.8524 - f1_m: 0.3540\n",
      "Epoch 43/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 597.7927 - f1_m: 0.3472\n",
      "Epoch 44/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 579.6556 - f1_m: 0.3455\n",
      "Epoch 45/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 685.5188 - f1_m: 0.3394\n",
      "Epoch 46/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 824.4653 - f1_m: 0.3451\n",
      "Epoch 47/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 793.4396 - f1_m: 0.3439\n",
      "Epoch 48/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 682.7958 - f1_m: 0.3342\n",
      "Epoch 49/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 419.1976 - f1_m: 0.3425\n",
      "Epoch 50/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 620.7927 - f1_m: 0.3189\n",
      "Epoch 51/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 381.1563 - f1_m: 0.3389\n",
      "Epoch 52/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 363.6659 - f1_m: 0.3497\n",
      "Epoch 53/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 506.9160 - f1_m: 0.3394\n",
      "Epoch 54/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 578.7624 - f1_m: 0.3227\n",
      "Epoch 55/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 415.8063 - f1_m: 0.3367\n",
      "Epoch 56/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 329.1330 - f1_m: 0.3326\n",
      "Epoch 57/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 295.6530 - f1_m: 0.3441\n",
      "Epoch 58/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 419.6065 - f1_m: 0.3348\n",
      "Epoch 59/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 504.2843 - f1_m: 0.3356\n",
      "Epoch 60/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 256.2957 - f1_m: 0.3352\n",
      "Epoch 61/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 273.2841 - f1_m: 0.3358\n",
      "Epoch 62/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 201.1958 - f1_m: 0.3386\n",
      "Epoch 63/150\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 224.2740 - f1_m: 0.3436\n",
      "Epoch 64/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 185.9688 - f1_m: 0.3552\n",
      "Epoch 65/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 175.4748 - f1_m: 0.3432\n",
      "Epoch 66/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 235.1736 - f1_m: 0.3313\n",
      "Epoch 67/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 167.9243 - f1_m: 0.3335\n",
      "Epoch 68/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 123.0990 - f1_m: 0.3541\n",
      "Epoch 69/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 113.7258 - f1_m: 0.3464\n",
      "Epoch 70/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 90.2854 - f1_m: 0.3535\n",
      "Epoch 71/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 120.4657 - f1_m: 0.3513\n",
      "Epoch 72/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 104.5431 - f1_m: 0.3421\n",
      "Epoch 73/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 78.3028 - f1_m: 0.3398\n",
      "Epoch 74/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 100.2193 - f1_m: 0.3408\n",
      "Epoch 75/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 75.6114 - f1_m: 0.3434\n",
      "Epoch 76/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 50.2493 - f1_m: 0.3388\n",
      "Epoch 77/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 43.1709 - f1_m: 0.3516\n",
      "Epoch 78/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 70.1936 - f1_m: 0.3454\n",
      "Epoch 79/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 55.5469 - f1_m: 0.3550\n",
      "Epoch 80/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 32.7335 - f1_m: 0.3475\n",
      "Epoch 81/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 50.6474 - f1_m: 0.3340\n",
      "Epoch 82/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 44.5557 - f1_m: 0.3551\n",
      "Epoch 83/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 29.4214 - f1_m: 0.3363\n",
      "Epoch 84/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 26.9603 - f1_m: 0.3563\n",
      "Epoch 85/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 29.5403 - f1_m: 0.3361\n",
      "Epoch 86/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 23.5570 - f1_m: 0.3415\n",
      "Epoch 87/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 21.3178 - f1_m: 0.3465\n",
      "Epoch 88/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 23.1410 - f1_m: 0.3487\n",
      "Epoch 89/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 24.3061 - f1_m: 0.3449\n",
      "Epoch 90/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 22.4438 - f1_m: 0.3442\n",
      "Epoch 91/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 20.7164 - f1_m: 0.3352\n",
      "Epoch 92/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 21.0536 - f1_m: 0.3416\n",
      "Epoch 93/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 17.0116 - f1_m: 0.3489\n",
      "Epoch 94/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 15.2266 - f1_m: 0.3431\n",
      "Epoch 95/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 21.1081 - f1_m: 0.3317\n",
      "Epoch 96/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 22.4076 - f1_m: 0.3256\n",
      "Epoch 97/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 20.8933 - f1_m: 0.3412\n",
      "Epoch 98/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 13.8820 - f1_m: 0.3428\n",
      "Epoch 99/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 16.9774 - f1_m: 0.3450\n",
      "Epoch 100/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 16.6482 - f1_m: 0.3280\n",
      "Epoch 101/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 11.9612 - f1_m: 0.3225\n",
      "Epoch 102/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 19.5732 - f1_m: 0.3326\n",
      "Epoch 103/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 12.6670 - f1_m: 0.3272\n",
      "Epoch 104/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 14.1911 - f1_m: 0.3273\n",
      "Epoch 105/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 10.2462 - f1_m: 0.3212\n",
      "Epoch 106/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 11.1557 - f1_m: 0.3056\n",
      "Epoch 107/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 13.4318 - f1_m: 0.3271\n",
      "Epoch 108/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 18.3339 - f1_m: 0.3250\n",
      "Epoch 109/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 11.3534 - f1_m: 0.3282\n",
      "Epoch 110/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 8.3108 - f1_m: 0.3149\n",
      "Epoch 111/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 9.3598 - f1_m: 0.3106\n",
      "Epoch 112/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 8.0613 - f1_m: 0.3169\n",
      "Epoch 113/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 11.3441 - f1_m: 0.3045\n",
      "Epoch 114/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 9.5159 - f1_m: 0.3091\n",
      "Epoch 115/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 12.1426 - f1_m: 0.3237\n",
      "Epoch 116/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 11.1417 - f1_m: 0.3061\n",
      "Epoch 117/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 10.7718 - f1_m: 0.3100\n",
      "Epoch 118/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 9.4755 - f1_m: 0.3131\n",
      "Epoch 119/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 7.2094 - f1_m: 0.3293\n",
      "Epoch 120/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 10.2115 - f1_m: 0.3051\n",
      "Epoch 121/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 7.5259 - f1_m: 0.2798\n",
      "Epoch 122/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 9.9002 - f1_m: 0.2977\n",
      "Epoch 123/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 11.2411 - f1_m: 0.3342\n",
      "Epoch 124/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 6.8767 - f1_m: 0.3022\n",
      "Epoch 125/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 6.3479 - f1_m: 0.2831\n",
      "Epoch 126/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 6.0325 - f1_m: 0.2775\n",
      "Epoch 127/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.9157 - f1_m: 0.2549\n",
      "Epoch 128/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 7.0610 - f1_m: 0.2842\n",
      "Epoch 129/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.8884 - f1_m: 0.2560\n",
      "Epoch 130/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 9.3443 - f1_m: 0.2959\n",
      "Epoch 131/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 3.8565 - f1_m: 0.2484\n",
      "Epoch 132/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 5.9033 - f1_m: 0.2679\n",
      "Epoch 133/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 7.7029 - f1_m: 0.2736\n",
      "Epoch 134/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 5.1354 - f1_m: 0.2556\n",
      "Epoch 135/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.3708 - f1_m: 0.2604\n",
      "Epoch 136/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 5.6234 - f1_m: 0.2691\n",
      "Epoch 137/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3.3540 - f1_m: 0.2583\n",
      "Epoch 138/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.7199 - f1_m: 0.2560\n",
      "Epoch 139/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.5831 - f1_m: 0.2620\n",
      "Epoch 140/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.2003 - f1_m: 0.2382\n",
      "Epoch 141/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.0857 - f1_m: 0.2480\n",
      "Epoch 142/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.3642 - f1_m: 0.2828\n",
      "Epoch 143/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.9186 - f1_m: 0.3033\n",
      "Epoch 144/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 4.3843 - f1_m: 0.2968\n",
      "Epoch 145/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3.7510 - f1_m: 0.2940\n",
      "Epoch 146/150\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 6.7928 - f1_m: 0.3155\n",
      "Epoch 147/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3.9047 - f1_m: 0.3115\n",
      "Epoch 148/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3.9465 - f1_m: 0.3140\n",
      "Epoch 149/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 2.9244 - f1_m: 0.3316\n",
      "Epoch 150/150\n",
      "120/120 [==============================] - 1s 6ms/step - loss: 3.7519 - f1_m: 0.3281\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f4483bbc130>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(_x_train, _y_train, epochs=150)  # with learning_rate=1e-4\n",
    "# model.fit(_x_train, _y_train, epochs=200)  # with learning_rate=1e-5\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# model.save(\"Models/cdt_2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 1.9021 - f1_m: 0.4157\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.902063250541687, 0.4156889021396637]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(_x_test, _y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(_x_test)\n",
    "pred_test_ind = np.argmax(pred_test, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test correct: 548\n",
      "Test accuracy: 0.4370015948963317\n"
     ]
    }
   ],
   "source": [
    "print(\"Test correct:\", np.sum(pred_test_ind == _y_test_ind))\n",
    "print(\"Test accuracy:\", np.sum(pred_test_ind == _y_test_ind)/pred_test_ind.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 29, 210,  37],\n       [126, 483,  91],\n       [ 38, 204,  36]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(_y_test_ind, pred_test_ind)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Valitation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 5ms/step - loss: 1.6282 - f1_m: 0.3883\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.6281975507736206, 0.38829827308654785]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(_x_validation, _y_validation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_validation = model.predict(_x_validation)\n",
    "pred_validation_ind = np.argmax(pred_validation, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation correct: 513\n",
      "Validation accuracy: 0.4090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation correct:\", np.sum(pred_validation_ind == _y_validation_ind))\n",
    "print(\"Validation accuracy:\", np.sum(pred_validation_ind == _y_validation_ind)/pred_validation_ind.shape[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 48, 264,  42],\n       [ 87, 404,  81],\n       [ 49, 218,  61]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(_y_validation_ind, pred_validation_ind)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
